There seem to be very few currently available, if any at all, systems of long-term care monitoring available. 

One possible idea is to have a smartwatch with integrated vital monitoring systems and an RFID tag either on the device or implanted in the patient. The entrances and exits to each room may have motion sensors so it is possible to track the patient to a specific room. Then, RFID readers mounted on walls and RSSI based proximity from these sources can be used to determine specific locations and probable current activity. NFC could be considered rather than RFID, but its operating distance is too small, and since individual tags would have to be mounted on each important piece of equipment, setup and configuration would be very complex and the price of the system would be much higher. 

One potential problem with this system is the cost and difficulty of implementation. A simpler, cheaper, but less sophisticated system relies on a series of networked cameras and microphones being controlled by a computer. An image processing library, perhaps, OpenCV, could be used to analyze the data. Perhaps the cameras would only capture an image every five minutes, unless a certain noise threshold is passed and then images are captured once every ten seconds.

Possible Platforms
==================
https://code.google.com/p/zephyropen/ - Open source Bluetooth health monitor
https://digarchive.library.vcu.edu/bitstream/handle/10156/2314/Ashwin_Belle_Thesis.pdf?sequence=1 - Paper on medical control with specifics
http://readwrite.com/2013/11/06/pebble-sdk-sensors-quantified-self#awesm=~oveuX94gRfVaG7 - Smartwatches with potential
http://www.medgadget.com/2012/07/lifewatch-v-android-based-healthcare-smartphone-packed-with-medical-sensors.html - Healthcare oriented Android phone
http://www.mdpi.com/1424-8220/11/7/6799/pdf - Android Healthcare Solution
http://medicarduino.net/ - Medical applications of the arduino
http://www.cs.odu.edu/~cs495/Papers/app-006.pdf - Cell phone medical applications
http://interaxon.ca/muse/faq.php - Headband full of sensors
http://www.cooking-hacks.com/documentation/tutorials/ehealth-biometric-sensor-platform-arduino-raspberry-pi-medical - RPi and Arduino health solutions
http://www.eecs.ucf.edu/isuelab/publications/pubs/wish2011.pdf - Patient tracking technology
http://spie.org/x102694.xml - Face tracking to detect patient state

Arduino Solution
================
I have a possible solution in mind that could provide many of the health metrics we need. The patient would wear a small, pokedex-sized device containing an Arduino board, its accessories, and a battery. Wires would be run out to various locations to connect component which could then be used to obtain various readings. For example, a heart rate monitor could be wired up and attached to the earlobe to provide information about heart rate. An LED might be connected and then attached to the shoulder to provide a light source for location tracking via a system of networked cameras strategically mounted in each room. An orientation sensor could be wired up along with the LED to provide information about the position and motion of the patient. When all of the information from these devices is collected, it provides a very good base for figuring out what is going on or what the patient is doing. For example, if the patient is lying horizontally, and has a lowered heart rate, and has been stationary for a long period of time, it could be inferred that the patient is sleeping. If the patient is not moving much, yet has a normal heart rate, and is in a specific location with a device such as a computer, it could be inferred that the patient is interacting with the computer. 

This solution provides information that can be used to determine a large amount about the current condition of a patient. However, it does require the patient to wear a device on them at all times. I also have a possible solution that does not require any sort of device to be worn on the patient. A system of networked cameras could intelligently capture images, and then process these images to try and determine the condition of the patient. For example, a camera could detect when the percentage of image change between several frames was greater than a certain threshold, capture and image and scan it, and upon completing a face recognition scan and surveying recent motion statistics, determine that the patient is sleeping because his or her eyes are closed and he or she has not moved in a while. Although the information provided will not be as high quality as that of the other solution, and the guesses and inferences will not be quite as accurate, this approach is completely noninvasive.

Jawbone UP Solution
===================
Another potential device that could be used is the Jawbone UP - in fact, it is a very good candidate for this sort of work because it provides an immense number of statistics - including sleep tracking, mobility tracking, mood tracking, nutrition tracking, and excercise tracking. It provides the metrics necessary for a large majority of what needs to be tracked and monitored. The only thing that it cannot track is the motion inside a house to a specific degree. Another drawback is that it needs to be connected by Bluetooth to an iOS or Android device. It costs $120 for the base model if bought directly from the website, and it costs $100 if bought on Amazon. The API is easily accessible, and is accessed in the form of JSON objects, so almost any programming language with adequate network support can be used to implement for it. In fact, it is not even necessary to implement a native app for the deployed device - all of it can be monitored and tracked with a centralized computer cluster which can provide a platform to view data about patients. A simple web interface could be implemented that would get the required information and do the necessary analysis to detrmine what would need to happen.
https://jawbone.com/up
https://jawbone.com/up/developer
https://jawbone.com/up/developer/endpoints

Based upon the above, the proposal is:

I have come up with a solution that leverages the capabilities of a currently-existing hardware and software platform. Using the Jawbone Up (jawbone.com/up), it would be possible to implement a powerful platform for gathering a number of metrics that could provide information about patients in an easy-to-read format. The patient would need to be wearing the wristband and be within about 15 feet of a pokedex or other Android or iOS device with Bluetooth capability. The API provided is a simple one that uses JSON objects to provide all the necessary information, so the implementation is not language bound; as long as the target language has support for networking, it should be quite easy to implement a system for procuring and analyzing the data. The main benefit of this approach is that the system can be centralized because a single cluster of computers would provide enough computation power for handling all of the patients' data; because all the cluster would be doing is getting information from the Jawbone service, processing it to determine what is going on with the patient, and then presenting it an easy-to-understand format for the caretaker or end user. The Jawbone Up provides all the necessary metrics to make fairly advanced predictions about the condition of the patient. There is no installation process required - the only necessary devices on the patient's end would be the wristband and a pokedex (which is most likely already in place). At our end, all we need are a couple of computers to pull the data from the cloud and analyze it, and a server to host the web interface. All of the necessary data can be quickly and easily obtained from the patient by simply pulling a JSON object from the patient's Jawbone cloud account - so the application can be deployed to multiple different platforms if necessary.


The current plan is to harness the sensory capabilities of the Jawbone UP to gather a large amount of data about the patient and their activity. The Jawbone provides capability to detect motion, heartrate, and sleep patterns. It also provides the capability to schedule goals based on sensory data (bedtime, a certain threshold of motion per day, etc). 
